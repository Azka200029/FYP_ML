{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=0\n",
    "# for i in range(10):\n",
    "#     for j in range(10):\n",
    "#         count+=1\n",
    "#         # Extract the average red values for the current block\n",
    "#         signal = selected_frames[i, j, :]\n",
    "#         print(f'Block {count} - Signal Shape: {signal.shape}')\n",
    "#         # print(signal.shape)\n",
    "#         print(signal)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import butter, filtfilt\n",
    "# # Define Butterworth filter parameters\n",
    "# nyquist_freq = fps / 2  # Nyquist frequency\n",
    "# cutoff_freq = 0.5  # Desired cutoff frequency in Hz\n",
    "# order = 2  # Filter order\n",
    "\n",
    "# # Compute normalized cutoff frequency\n",
    "# normalized_cutoff_freq = cutoff_freq / nyquist_freq\n",
    "\n",
    "# # Apply Butterworth filter\n",
    "# b, a = butter(order, normalized_cutoff_freq, btype='low', analog=False)\n",
    "# filtered_signals = filtfilt(b, a, Su, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.fft import fft, ifft\n",
    "\n",
    "# # Define the frequency range\n",
    "# low_freq = 0.5  # Lower cutoff frequency in Hz\n",
    "# high_freq = 5.0  # Higher cutoff frequency in Hz\n",
    "\n",
    "# # Compute the frequency corresponding to each index of the FFT\n",
    "# n = len(Su[0, 0])  # Length of each PPG signal\n",
    "# freq = np.fft.fftfreq(n)\n",
    "\n",
    "# # Initialize the filtered PPG signals\n",
    "# Sc = np.zeros_like(Su)\n",
    "\n",
    "# # Apply FFT to each PPG signal\n",
    "# for i in range(Su.shape[0]):  # Iterate over blocks\n",
    "#     for j in range(Su.shape[1]):\n",
    "#         ppg_signal = Su[i, j, :]\n",
    "#         fft_signal = fft(ppg_signal)\n",
    "        \n",
    "#         # Identify indices corresponding to frequencies outside the desired range\n",
    "#         unwanted_indices = (freq < low_freq) | (freq > high_freq)\n",
    "        \n",
    "#         # Set those frequency components to zero\n",
    "#         fft_signal[unwanted_indices] = 0\n",
    "        \n",
    "#         # Apply inverse FFT to get the filtered signal\n",
    "#         filtered_signal = ifft(fft_signal)\n",
    "        \n",
    "#         # Store the filtered signal\n",
    "#         Sc[i, j, :] = filtered_signal.real  # Take the real part to avoid imaginary components\n",
    "\n",
    "# # Sc now contains the filtered PPG signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "from scipy import fftpack\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sampling rate (r) and duration of the signal need to be defined based on your video analysis\n",
    "r = fps  # frames per second from video metadata\n",
    "duration = frame_count / r  # Duration of the video in seconds\n",
    "\n",
    "# Generate a Butterworth filter\n",
    "lowcut = 0.5  # Low frequency threshold (Hz)\n",
    "highcut = 5.0  # High frequency threshold (Hz)\n",
    "nyquist = 0.5 * r\n",
    "low = lowcut / nyquist\n",
    "high = highcut / nyquist\n",
    "b, a = butter(3, [low, high], btype='band')\n",
    "\n",
    "# Apply Butterworth filter (assuming 'signal' is your PPG signal extracted from the video)\n",
    "filtered_signal = filtfilt(b, a, selected_frames)\n",
    "\n",
    "# Apply FFT and remove frequencies outside the desired range\n",
    "W = fftpack.fft(filtered_signal)\n",
    "frequencies = fftpack.fftfreq(len(filtered_signal), 1/r)\n",
    "\n",
    "# Zero out frequencies outside the desired range\n",
    "W[(frequencies < lowcut) | (frequencies > highcut)] = 0\n",
    "\n",
    "# Get the filtered signal back\n",
    "clean_signal = fftpack.ifft(W)\n",
    "\n",
    "# Normalize and invert the signal to match hemoglobin level relationship\n",
    "Sc = np.abs(clean_signal)  # Taking absolute value to handle complex result from ifft\n",
    "SPG = Sc * -1  # Inverting the signal\n",
    "\n",
    "# SPG is now your processed PPG signal ready for further analysis\n",
    "SPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming SPG is of shape (10, 10, num_frames) where num_frames is the length after selecting frames 51 to 550\n",
    "# Average across all blocks\n",
    "avg_signal = np.mean(SPG, axis=(0, 1))  # This averages the signal across the first two dimensions (all blocks)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_signal, label='Average Processed PPG Signal')\n",
    "plt.title('Average Processed PPG Signal')\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Signal Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_ppg_cycles_for_one_signal(sppg_signal, sampling_rate):\n",
    "    ppg_cycles = []\n",
    "\n",
    "    peaks, _ = find_peaks(sppg_signal)\n",
    "    valleys, _ = find_peaks(-sppg_signal)\n",
    "\n",
    "    # Ensure peaks and valleys are not empty\n",
    "    if len(peaks) == 0 or len(valleys) == 0:\n",
    "        return ppg_cycles\n",
    "\n",
    "    # Plot the PPG signal\n",
    "    plt.figure()\n",
    "    plt.plot(sppg_signal, label='PPG Signal')\n",
    "\n",
    "    # Mark peaks and valleys differently\n",
    "    plt.scatter(peaks, sppg_signal[peaks], color='red', marker='o', label='Peaks')\n",
    "    plt.scatter(valleys, sppg_signal[valleys], color='blue', marker='x', label='Valleys')\n",
    "\n",
    "    # Plot the legend\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('PPG Signal Value')\n",
    "    plt.title('Detected Peaks and Valleys')\n",
    "    plt.show()\n",
    "\n",
    "    return ppg_cycles\n",
    "\n",
    "# Example usage\n",
    "sampling_rate = fps \n",
    "sppg_signal = SPPG[0, 0, :]  # Assuming we are processing the first PPG signal\n",
    "ppg_cycles = detect_ppg_cycles_for_one_signal(sppg_signal, sampling_rate)\n",
    "print(\"Detected PPG cycles:\", ppg_cycles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_ppg_cycles_for_one_signal(sppg_signal, sampling_rate):\n",
    "    ppg_cycles = []\n",
    "\n",
    "    peaks, _ = find_peaks(sppg_signal)\n",
    "    valleys, _ = find_peaks(-sppg_signal)\n",
    "\n",
    "    # Ensure peaks and valleys are not empty\n",
    "    if len(peaks) == 0 or len(valleys) == 0:\n",
    "        return ppg_cycles\n",
    "\n",
    "    # Plot the PPG signal\n",
    "    plt.figure()\n",
    "    plt.plot(sppg_signal, label='PPG Signal')\n",
    "\n",
    "    # Calculate peak and valley heights\n",
    "    peak_heights = sppg_signal[peaks]\n",
    "    valley_heights = sppg_signal[valleys]\n",
    "\n",
    "    # Find the maximum peak and minimum valley heights\n",
    "    max_peak_height = max(peak_heights)\n",
    "    min_valley_height = min(valley_heights)\n",
    "\n",
    "    # Mark peaks and valleys differently based on their heights\n",
    "    for peak, peak_height in zip(peaks, peak_heights):\n",
    "        if peak_height == max_peak_height:\n",
    "            marker = 's'  # Systolic peak marker style\n",
    "            color = 'red'  # Systolic peak color\n",
    "        else:\n",
    "            marker = 'o'  # Diastolic peak marker style\n",
    "            color = 'blue'  # Diastolic peak color\n",
    "        plt.scatter(peak, sppg_signal[peak], color=color, marker=marker, label='Peaks')\n",
    "\n",
    "    for valley in valleys:\n",
    "        plt.scatter(valley, sppg_signal[valley], color='green', marker='x', label='Valleys')\n",
    "\n",
    "    # Plot the legend\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('PPG Signal Value')\n",
    "    plt.title('Detected Peaks and Valleys')\n",
    "    plt.show()\n",
    "\n",
    "    return ppg_cycles\n",
    "\n",
    "# Example usage\n",
    "sampling_rate = fps \n",
    "sppg_signal = SPPG[0, 0, :]  # Assuming we are processing the first PPG signal\n",
    "ppg_cycles = detect_ppg_cycles_for_one_signal(sppg_signal, sampling_rate)\n",
    "print(\"Detected PPG cycles:\", ppg_cycles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_ppg_cycles_for_one_signal(sppg_signal, sampling_rate):\n",
    "    ppg_cycles = []\n",
    "\n",
    "    peaks, _ = find_peaks(sppg_signal)\n",
    "    valleys, _ = find_peaks(-sppg_signal)\n",
    "\n",
    "    # Ensure peaks and valleys are not empty\n",
    "    if len(peaks) == 0 or len(valleys) == 0:\n",
    "        return ppg_cycles\n",
    "\n",
    "    # Find consecutive minima and maxima\n",
    "    for peak_idx in range(len(peaks) - 1):\n",
    "        for valley_idx in range(len(valleys) - 1):\n",
    "            start_idx = valleys[valley_idx]\n",
    "            end_idx = valleys[valley_idx + 1]\n",
    "\n",
    "            # Check if the current peak is within the current valley\n",
    "            if start_idx < peaks[peak_idx] < end_idx:\n",
    "                systolic_peak = peaks[peak_idx]\n",
    "                diastolic_peak = peaks[peak_idx + 1]\n",
    "                start_point = start_idx\n",
    "                end_point = valleys[valley_idx + 2]\n",
    "                dicrotic_notch = valleys[valley_idx+1]\n",
    "\n",
    "                # # Check conditions for valid PPG cycle\n",
    "                # if (sppg_signal[systolic_peak] > sppg_signal[diastolic_peak] and\n",
    "                #     sppg_signal[dicrotic_notch] > sppg_signal[start_point] and\n",
    "                #     sppg_signal[dicrotic_notch] > sppg_signal[end_point]):\n",
    "\n",
    "                #     # Calculate time elapsed for PPG cycle\n",
    "                #     cycle_time = (end_point - start_point) / sampling_rate\n",
    "                #     expected_cycle_time = get_expected_cycle_time(sppg_signal, sampling_rate)\n",
    "                #     error_margin = 0.2 * expected_cycle_time\n",
    "\n",
    "                #     # Check if time elapsed is within threshold\n",
    "                #     if abs(cycle_time - expected_cycle_time) <= error_margin:\n",
    "                #         ppg_cycles.append((start_point, systolic_peak, dicrotic_notch, diastolic_peak, end_point))\n",
    "\n",
    "                # Plot the PPG signal with markers for peaks and valleys\n",
    "                plt.figure()\n",
    "                plt.plot(sppg_signal)\n",
    "                # plt.scatter([start_point, systolic_peak, dicrotic_notch, diastolic_peak, end_point], \n",
    "                #             [sppg_signal[start_point], sppg_signal[systolic_peak], sppg_signal[dicrotic_notch], sppg_signal[diastolic_peak], sppg_signal[end_point]], \n",
    "                #             color='red', marker='o')\n",
    "                \n",
    "\n",
    "                 # Mark each point with a different marker\n",
    "                plt.scatter(start_point, sppg_signal[start_point], color='green', marker='^', label='Start Point')\n",
    "                plt.scatter(systolic_peak, sppg_signal[systolic_peak], color='orange', marker='s', label='Systolic Peak')\n",
    "                plt.scatter(dicrotic_notch, sppg_signal[dicrotic_notch], color='purple', marker='*', label='Dicrotic Notch')\n",
    "                plt.scatter(diastolic_peak, sppg_signal[diastolic_peak], color='pink', marker='d', label='Diastolic Peak')\n",
    "                plt.scatter(end_point, sppg_signal[end_point], color='black', marker='P', label='End Point')\n",
    "                plt.xlabel('Sample Index')\n",
    "                plt.ylabel('PPG Signal Value')\n",
    "                plt.title('Detected PPG Cycles')\n",
    "                # plt.legend(['PPG Signal', 'Peaks and Valleys'])\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "    return ppg_cycles\n",
    "\n",
    "# Example usage\n",
    "sampling_rate = fps \n",
    "sppg_signal = SPPG[0, 0, :]  # Assuming we are processing the first PPG signal\n",
    "ppg_cycles = detect_ppg_cycles_for_one_signal(sppg_signal, sampling_rate)\n",
    "print(\"Detected PPG cycles:\", ppg_cycles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "def get_expected_cycle_time(ppg_signal, sampling_rate):\n",
    "    # Compute the FFT of the PPG signal\n",
    "    fft_signal = fft(ppg_signal)\n",
    "    \n",
    "    # Compute the frequency spectrum and corresponding frequencies\n",
    "    n = len(ppg_signal)\n",
    "    freq = fftfreq(n, d=1/sampling_rate)\n",
    "    \n",
    "    # Find the index of the dominant frequency component\n",
    "    dominant_freq_idx = np.argmax(np.abs(fft_signal))\n",
    "    \n",
    "    # Calculate the period of the dominant frequency component\n",
    "    dominant_freq = freq[dominant_freq_idx]\n",
    "    if dominant_freq == 0:\n",
    "        # Avoid division by zero when the dominant frequency is 0 Hz\n",
    "        return np.inf\n",
    "    expected_period = 1 / dominant_freq\n",
    "    \n",
    "    # Convert period to cycle time (in seconds)\n",
    "    expected_cycle_time = expected_period\n",
    "    \n",
    "    return expected_cycle_time\n",
    "\n",
    "\n",
    "def detect_ppg_cycles_for_one_signal(sppg_signal, sampling_rate):\n",
    "    ppg_cycles = []\n",
    "\n",
    "    peaks, _ = find_peaks(sppg_signal)\n",
    "    valleys, _ = find_peaks(-sppg_signal)\n",
    "\n",
    "    # Ensure peaks and valleys are not empty\n",
    "    if len(peaks) == 0 or len(valleys) == 0:\n",
    "        return ppg_cycles\n",
    "\n",
    "    # Find consecutive minima and maxima\n",
    "    for peak_idx in range(len(peaks) - 1):\n",
    "        for valley_idx in range(len(valleys) - 1):\n",
    "            start_idx = valleys[valley_idx]\n",
    "            end_idx = valleys[valley_idx + 1]\n",
    "\n",
    "            # Check if the current peak is within the current valley\n",
    "            if start_idx < peaks[peak_idx] < end_idx:\n",
    "                systolic_peak = peaks[peak_idx]\n",
    "                diastolic_peak = peaks[peak_idx + 1]\n",
    "                start_point = start_idx\n",
    "                end_point = end_idx\n",
    "                dicrotic_notch = valleys[valley_idx]\n",
    "\n",
    "                # Check conditions for valid PPG cycle\n",
    "                if (sppg_signal[systolic_peak] > sppg_signal[diastolic_peak] and\n",
    "                    sppg_signal[dicrotic_notch] > sppg_signal[start_point] and\n",
    "                    sppg_signal[dicrotic_notch] > sppg_signal[end_point]):\n",
    "\n",
    "                    # Calculate time elapsed for PPG cycle\n",
    "                    cycle_time = (end_point - start_point) / sampling_rate\n",
    "                    expected_cycle_time = get_expected_cycle_time(sppg_signal, sampling_rate)\n",
    "                    error_margin = 0.2 * expected_cycle_time\n",
    "\n",
    "                    # Check if time elapsed is within threshold\n",
    "                    if abs(cycle_time - expected_cycle_time) <= error_margin:\n",
    "                        ppg_cycles.append((start_point, systolic_peak, dicrotic_notch, diastolic_peak, end_point))\n",
    "\n",
    "    return ppg_cycles\n",
    "\n",
    "# Example usage\n",
    "sampling_rate = fps \n",
    "sppg_signal = SPPG[0, 0, :]  # Assuming we are processing the first PPG signal\n",
    "ppg_cycles = detect_ppg_cycles_for_one_signal(sppg_signal, sampling_rate)\n",
    "print(\"Detected PPG cycles:\", ppg_cycles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_ppg_cycles(SPPG, sampling_rate):\n",
    "    ppg_cycles = []\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            sppg_signal = SPPG[i, j, :]\n",
    "            peaks, _ = find_peaks(sppg_signal)\n",
    "            valleys, _ = find_peaks(-sppg_signal)\n",
    "\n",
    "            # Ensure peaks and valleys are not empty\n",
    "            if len(peaks) == 0 or len(valleys) == 0:\n",
    "                continue\n",
    "\n",
    "            # Find consecutive minima and maxima\n",
    "            for peak_idx in range(len(peaks) - 1):\n",
    "                for valley_idx in range(len(valleys) - 1):\n",
    "                    start_idx = valleys[valley_idx]\n",
    "                    end_idx = valleys[valley_idx + 1]\n",
    "\n",
    "                    # Check if the current peak is within the current valley\n",
    "                    if start_idx < peaks[peak_idx] < end_idx:\n",
    "                        systolic_peak = peaks[peak_idx]\n",
    "                        diastolic_peak = peaks[peak_idx + 1]\n",
    "                        start_point = start_idx\n",
    "                        end_point = end_idx\n",
    "                        dicrotic_notch = valleys[valley_idx]\n",
    "\n",
    "                        # Check conditions for valid PPG cycle\n",
    "                        if (sppg_signal[systolic_peak] > sppg_signal[diastolic_peak] and\n",
    "                            sppg_signal[dicrotic_notch] > sppg_signal[start_point] and\n",
    "                            sppg_signal[dicrotic_notch] > sppg_signal[end_point]):\n",
    "\n",
    "                            # Calculate time elapsed for PPG cycle\n",
    "                            cycle_time = (end_point - start_point) / sampling_rate\n",
    "                            expected_cycle_time = get_expected_cycle_time(sppg_signal)\n",
    "                            error_margin = 0.2 * expected_cycle_time\n",
    "\n",
    "                            # Check if time elapsed is within threshold\n",
    "                            if abs(cycle_time - expected_cycle_time) <= error_margin:\n",
    "                                ppg_cycles.append((start_point, systolic_peak, dicrotic_notch, diastolic_peak, end_point))\n",
    "\n",
    "    return ppg_cycles\n",
    "\n",
    "def get_expected_cycle_time(ppg_signal):\n",
    "    # Logic to calculate expected cycle time from FFT of PPG signal\n",
    "    # This function needs to be implemented based on the FFT results\n",
    "    return expected_cycle_time\n",
    "\n",
    "# Example usage\n",
    "sampling_rate = 30  # Sample rate in Hz (assumed)\n",
    "ppg_cycles = detect_ppg_cycles(SPPG, sampling_rate)\n",
    "print(\"Detected PPG cycles:\", ppg_cycles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def merge_ppg_cycles(selected_cycles):\n",
    "    num_cycles = len(selected_cycles)\n",
    "    # print(\"Number of cycles:\", num_cycles)\n",
    "    if num_cycles == 0:\n",
    "        return None\n",
    "    \n",
    "    cycle_length = selected_cycles[0][4] - selected_cycles[0][0] + 1\n",
    "    print(\"Cycle length:\", cycle_length)\n",
    "    print(\"selected_cycles[0]][0]:\", selected_cycles[0][0])\n",
    "    print(\"selected_cycles[0][4]:\", selected_cycles[0][4])\n",
    "    merged_signal = np.zeros(cycle_length)\n",
    "    \n",
    "    # Iterate over each selected cycle and add their values together\n",
    "    for cycle in selected_cycles:\n",
    "        start_idx, systolic_peak_idx, dicrotic_notch_idx, diastolic_peak_idx, end_idx = cycle\n",
    "        cycle_signal = sppg_signal[start_idx:end_idx+1]\n",
    "        print(\"cycle_signal:\", cycle_signal)\n",
    "        merged_signal[:len(cycle_signal)] += cycle_signal\n",
    "    \n",
    "    # Take the average of the summed signals\n",
    "    merged_signal /= num_cycles\n",
    "    \n",
    "    return merged_signal\n",
    "\n",
    "# Example usage\n",
    "merged_signal = merge_ppg_cycles(selected_cycles)\n",
    "print(\"Merged PPG signal:\", merged_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features(merged_signal, sampling_rate):\n",
    "#     all_features = []\n",
    "\n",
    "#     if merged_signal is None:\n",
    "#         return None\n",
    "    \n",
    "#     # Smooth the merged signal using Savitzky-Golay filtering\n",
    "#     smoothed_signal = savgol_filter(merged_signal, window_length=15, polyorder=3)\n",
    "\n",
    "#     # Compute the 1st and 2nd derivatives of the smoothed signal\n",
    "#     first_derivative = np.gradient(smoothed_signal)\n",
    "#     second_derivative = np.gradient(first_derivative)\n",
    "\n",
    "#     # Find peaks and valleys in the smoothed signal\n",
    "#     peaks, _ = find_peaks(smoothed_signal, distance=int(sampling_rate * 0.5))\n",
    "#     valleys, _ = find_peaks(-smoothed_signal, distance=int(sampling_rate * 0.5))\n",
    "\n",
    "#     # Compute various features from the signal and its derivatives\n",
    "#     features = []\n",
    "\n",
    "#         # Systolic peak height\n",
    "#     systolic_peak_height = np.max(smoothed_signal)\n",
    "#     features.append(systolic_peak_height)\n",
    "\n",
    "#     # Diatolic peak height\n",
    "#     diatolic_peak_height = np.min(smoothed_signal[valleys])\n",
    "#     features.append(diatolic_peak_height)\n",
    "\n",
    "#     # Dicrotic notch height\n",
    "#     dicrotic_notch_height = smoothed_signal[peaks][1] - smoothed_signal[valleys][1]\n",
    "#     features.append(dicrotic_notch_height)\n",
    "\n",
    "#     # Pulse interval\n",
    "#     pulse_interval = (peaks[1] - peaks[0]) / sampling_rate\n",
    "#     features.append(pulse_interval)\n",
    "\n",
    "#     # Augmentation index\n",
    "#     augmentation_index = (systolic_peak_height - diatolic_peak_height) / diatolic_peak_height * 100\n",
    "#     features.append(augmentation_index)\n",
    "\n",
    "#     # Relative augmentation index\n",
    "#     relative_augmentation_index = (systolic_peak_height - diatolic_peak_height) / systolic_peak_height * 100\n",
    "#     features.append(relative_augmentation_index)\n",
    "\n",
    "#     # Ratio of z and x\n",
    "#     z_x_ratio = dicrotic_notch_height / systolic_peak_height\n",
    "#     features.append(z_x_ratio)\n",
    "\n",
    "#     # Negative relative augmentation index\n",
    "#     negative_relative_augmentation_index = (diatolic_peak_height - systolic_peak_height) / diatolic_peak_height * 100\n",
    "#     features.append(negative_relative_augmentation_index)\n",
    "\n",
    "#     # Systolic peak time\n",
    "#     systolic_peak_time = peaks[0] / sampling_rate\n",
    "#     features.append(systolic_peak_time)\n",
    "\n",
    "#     # Dicrotic notch time\n",
    "#     dicrotic_notch_time = peaks[1] / sampling_rate\n",
    "#     features.append(dicrotic_notch_time)\n",
    "\n",
    "#     # Diastolic peak time\n",
    "#     diastolic_peak_time = valleys[0] / sampling_rate\n",
    "#     features.append(diastolic_peak_time)\n",
    "\n",
    "#     # Time between systolic and diastolic peaks\n",
    "#     time_between_peaks = (peaks[0] - valleys[0]) / sampling_rate\n",
    "#     features.append(time_between_peaks)\n",
    "\n",
    "#     # Time between half systolic peak points\n",
    "#     half_systolic_peak_time = (peaks[0] - valleys[1]) / sampling_rate\n",
    "#     features.append(half_systolic_peak_time)\n",
    "\n",
    "#     # Inflection point area ratio\n",
    "#     inflection_point_area_ratio = np.trapz(smoothed_signal[valleys[0]:peaks[1]]) / np.trapz(smoothed_signal[peaks[0]:valleys[0]])\n",
    "#     features.append(inflection_point_area_ratio)\n",
    "    \n",
    "#     # Systolic peak rising slope\n",
    "#     systolic_peak_rising_slope = (smoothed_signal[peaks[0]] - smoothed_signal[valleys[0]]) / time_between_peaks\n",
    "#     features.append(systolic_peak_rising_slope)\n",
    "    \n",
    "#     # Diatolic peak falling slope\n",
    "#     diatolic_peak_falling_slope = (smoothed_signal[valleys[0]] - smoothed_signal[peaks[1]]) / time_between_peaks\n",
    "#     features.append(diatolic_peak_falling_slope)\n",
    "    \n",
    "#     # Ratio of t1 and pulse interval time (tpi)\n",
    "#     t1_tpi_ratio = time_between_peaks / pulse_interval\n",
    "#     features.append(t1_tpi_ratio)\n",
    "\n",
    "#     # Ratio of t2 and pulse interval time (tpi)\n",
    "#     t2_tpi_ratio = half_systolic_peak_time / pulse_interval\n",
    "#     features.append(t2_tpi_ratio)\n",
    "\n",
    "#     # Ratio of t3 and pulse interval time (tpi)\n",
    "#     t3_tpi_ratio = (peaks[1] - valleys[1]) / sampling_rate / pulse_interval\n",
    "#     features.append(t3_tpi_ratio)\n",
    "\n",
    "#     # Ratio of deltaT and pulse interval time (tpi)\n",
    "#     deltaT_tpi_ratio = (valleys[1] - peaks[0]) / sampling_rate / pulse_interval\n",
    "#     features.append(deltaT_tpi_ratio)\n",
    "    \n",
    "#     # Interval time from first PPG cycle start point (l1) in first derivative of PPF (Sf) to first maxima (a1) of Sf\n",
    "#     ta1 = peaks[0] - valleys[0]\n",
    "#     features.append(ta1)\n",
    "\n",
    "#     # Interval time from point l1 to first minima of first PPG cycle (b1) in the Sf\n",
    "#     tb1 = valleys[0] - peaks[0]\n",
    "#     features.append(tb1)\n",
    "    \n",
    "#     # Interval time from point l1 to second minima of the first PPG cycle (f1) in the Sf\n",
    "#     tf1 = valleys[1] - peaks[0]\n",
    "#     features.append(tf1)\n",
    "    \n",
    "#     # Ratio of first minima (b2) and first maxima (a2) in the second derivative of PPG signal (Sf2)\n",
    "#     b2_a2_ratio = second_derivative[valleys[0]] / second_derivative[peaks[0]]\n",
    "#     features.append(b2_a2_ratio)\n",
    "    \n",
    "#     # Ratio od second maxima (e2) in Sf2 and a2\n",
    "#     e2_a2_ratio = second_derivative[peaks[1]] / second_derivative[peaks[0]]\n",
    "#     features.append(e2_a2_ratio)\n",
    "    \n",
    "#     # Ratio of (b2+e2) and a2 [40]\n",
    "#     b2_e2_a2_ratio = (second_derivative[valleys[0]] + second_derivative[peaks[1]]) / second_derivative[peaks[0]]\n",
    "#     features.append(b2_e2_a2_ratio)\n",
    "    \n",
    "#     # Interval time from the second PPG cycle start point (l2) in second derivative of PPG to a2\n",
    "#     ta2 = peaks[0] - valleys[0]\n",
    "#     features.append(ta2)\n",
    "    \n",
    "#     # Interval time from point l2 ti b2\n",
    "#     tb2 = valleys[0] - peaks[0]\n",
    "#     features.append(tb2)\n",
    "    \n",
    "#     # Ratio of ta1 and tpi\n",
    "#     ta1_tpi_ratio = ta1 / pulse_interval\n",
    "#     features.append(ta1_tpi_ratio)\n",
    "    \n",
    "#     # Ratio of tb1 and tpi\n",
    "#     tb1_tpi_ratio = tb1 / pulse_interval\n",
    "#     features.append(tb1_tpi_ratio)\n",
    "    \n",
    "#     # Ratio of te1 and tpi\n",
    "#     te1_tpi_ratio = (valleys[1] - peaks[0]) / sampling_rate / pulse_interval\n",
    "#     features.append(te1_tpi_ratio)\n",
    "    \n",
    "#     # Ratio of time interval of l1 (tl1) and tpi\n",
    "#     tl1_tpi_ratio = valleys[0] / sampling_rate / pulse_interval\n",
    "#     features.append(tl1_tpi_ratio)\n",
    "    \n",
    "#     # Ratio of ta2 and tpi\n",
    "#     ta2_tpi_ratio = ta2 / pulse_interval\n",
    "#     features.append(ta2_tpi_ratio)\n",
    "    \n",
    "#     # Ratio of tb2 and tpi\n",
    "#     tb2_tpi_ratio = tb2 / pulse_interval\n",
    "#     features.append(tb2_tpi_ratio)\n",
    "    \n",
    "#     # Ratio of ta1+ta2 and pulse interval (tpi)\n",
    "#     ta1_ta2_tpi_ratio = (ta1 + ta2) / pulse_interval\n",
    "#     features.append(ta1_ta2_tpi_ratio)\n",
    "    \n",
    "#     # Ratio of (tb1+tb2) and pulse interval (tpi)\n",
    "#     tb1_tb2_tpi_ratio = (tb1 + tb2) / pulse_interval \n",
    "#     features.append(tb1_tb2_tpi_ratio)\n",
    "       \n",
    "#     # Ratio of (te1+t2) and pulse interval (tpi)\n",
    "#     te1_te2_tpi_ratio = (te1_tpi_ratio + tb2_tpi_ratio)\n",
    "#     features.append(te1_te2_tpi_ratio)\n",
    "    \n",
    "#     # Ratio of tl1+t3 and pulse interval (tpi)\n",
    "#     tl1_t3_tpi_ratio = (tl1_tpi_ratio + t3_tpi_ratio)\n",
    "#     features.append(tl1_t3_tpi_ratio)\n",
    "    \n",
    "#     # Fundamental component frequency obtained from Fast Fourier Transformation (FFT)\n",
    "#     fbase = np.argmax(fft(smoothed_signal))\n",
    "#     features.append(fbase)\n",
    "    \n",
    "#     # Fundamental component magnitude from FFT\n",
    "#     fbase_magnitude = np.max(fft(smoothed_signal))\n",
    "#     features.append(fbase_magnitude)\n",
    "    \n",
    "#     # Second component frequency obtained from FFT. Such that, fbase<f2nd\n",
    "#     f2nd = np.argmax(fft(smoothed_signal[fbase:]))\n",
    "#     features.append(f2nd)\n",
    "    \n",
    "#     # Second component magnitude from FFT\n",
    "#     f2nd_magnitude = np.max(fft(smoothed_signal[fbase:]))\n",
    "#     features.append(f2nd_magnitude)\n",
    "    \n",
    "#     # Third component frequency obtained from FFT. Such that, fbase<f2nd<f3rd\n",
    "#     f3rd = np.argmax(fft(smoothed_signal[f2nd:]))\n",
    "#     features.append(f3rd)\n",
    "    \n",
    "#     # Third component magnitude acquired from FFT\n",
    "#     f3rd_magnitude = np.max(fft(smoothed_signal[f2nd:]))\n",
    "#     features.append(f3rd_magnitude)\n",
    "\n",
    "#         # Append features to the list\n",
    "\n",
    "\n",
    "#     all_features.append(features)\n",
    "\n",
    "#     return all_features\n",
    "\n",
    "# # Example usage\n",
    "# sampling_rate = 1000  # Sample rate in Hz\n",
    "\n",
    "# # Assuming merged_signals is a list containing merged signals for each PPG signal\n",
    "# # merged_signals = [merged_signal1, merged_signal2, merged_signal3, ...]\n",
    "\n",
    "# # Extract features for each merged signal\n",
    "# extracted_features = extract_features(merged_signal, sampling_rate)\n",
    "\n",
    "# # Visualize or process the extracted features as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features(merged_signal, sampling_rate):\n",
    "#     if merged_signal is None:\n",
    "#         return []  # Return an empty list when merged_signal is None\n",
    "    \n",
    "#     all_features = []\n",
    "\n",
    "    # # Smooth the merged signal using Savitzky-Golay filtering\n",
    "    # smoothed_signal = savgol_filter(merged_signal, window_length=15, polyorder=3)\n",
    "\n",
    "    # # Compute the 1st and 2nd derivatives of the smoothed signal\n",
    "    # first_derivative = np.gradient(smoothed_signal)\n",
    "    # second_derivative = np.gradient(first_derivative)\n",
    "\n",
    "    # # Find peaks and valleys in the smoothed signal\n",
    "    # peaks, _ = find_peaks(smoothed_signal, distance=int(sampling_rate * 0.5))\n",
    "    # valleys, _ = find_peaks(-smoothed_signal, distance=int(sampling_rate * 0.5))\n",
    "\n",
    "    # print(\"Peaks:\", peaks)\n",
    "    # print(\"Valleys:\", valleys)\n",
    "\n",
    "\n",
    "    # # Systolic peak height\n",
    "    # systolic_peak_height = np.max(smoothed_signal)\n",
    "    # all_features.append(systolic_peak_height)\n",
    "\n",
    "    # # Diatolic peak height\n",
    "    # diastolic_peak_height = np.min(smoothed_signal[valleys])\n",
    "    # all_features.append(diastolic_peak_height)\n",
    "\n",
    "    # print(smoothed_signal[peaks], smoothed_signal[valleys])\n",
    "\n",
    "    # # Dicrotic notch height\n",
    "    # dicrotic_notch_height = smoothed_signal[peaks][1] - smoothed_signal[valleys][1]\n",
    "    # all_features.append(dicrotic_notch_height)\n",
    "\n",
    "    # # Pulse interval\n",
    "    # pulse_interval = (peaks[1] - peaks[0]) / sampling_rate\n",
    "    # all_features.append(pulse_interval)\n",
    "\n",
    "    # # Augmentation index\n",
    "    # augmentation_index = (systolic_peak_height - diastolic_peak_height) / diastolic_peak_height * 100\n",
    "    # all_features.append(augmentation_index)\n",
    "\n",
    "    # # Relative augmentation index\n",
    "    # relative_augmentation_index = (systolic_peak_height - diastolic_peak_height) / systolic_peak_height * 100\n",
    "    # all_features.append(relative_augmentation_index)\n",
    "\n",
    "    # # Ratio of z and x\n",
    "    # z_x_ratio = dicrotic_notch_height / systolic_peak_height\n",
    "    # all_features.append(z_x_ratio)\n",
    "\n",
    "    # # Negative relative augmentation index\n",
    "    # negative_relative_augmentation_index = (diastolic_peak_height - systolic_peak_height) / diastolic_peak_height * 100\n",
    "    # all_features.append(negative_relative_augmentation_index)\n",
    "\n",
    "    # # Systolic peak time\n",
    "    # systolic_peak_time = peaks[0] / sampling_rate\n",
    "    # all_features.append(systolic_peak_time)\n",
    "\n",
    "    # # Dicrotic notch time\n",
    "    # dicrotic_notch_time = peaks[1] / sampling_rate\n",
    "    # all_features.append(dicrotic_notch_time)\n",
    "\n",
    "    # # Diastolic peak time\n",
    "    # diastolic_peak_time = valleys[0] / sampling_rate\n",
    "    # all_features.append(diastolic_peak_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # Time between systolic and diastolic peaks\n",
    "    # time_between_peaks = (peaks[0] - valleys[0]) / sampling_rate\n",
    "    # features.append(time_between_peaks)\n",
    "\n",
    "    # # Time between half systolic peak points\n",
    "    # half_systolic_peak_time = (peaks[0] - valleys[1]) / sampling_rate\n",
    "    # # features.append(half_systolic_peak_time)\n",
    "\n",
    "    # # Inflection point area ratio\n",
    "    # inflection_point_area_ratio = np.trapz(smoothed_signal[valleys[0]:peaks[1]]) / np.trapz(smoothed_signal[peaks[0]:valleys[0]])\n",
    "    # features.append(inflection_point_area_ratio)\n",
    "    \n",
    "    # # Systolic peak rising slope\n",
    "    # systolic_peak_rising_slope = (smoothed_signal[peaks[0]] - smoothed_signal[valleys[0]]) / time_between_peaks\n",
    "    # features.append(systolic_peak_rising_slope)\n",
    "    \n",
    "    # # Diatolic peak falling slope\n",
    "    # diatolic_peak_falling_slope = (smoothed_signal[valleys[0]] - smoothed_signal[peaks[1]]) / time_between_peaks\n",
    "    # features.append(diatolic_peak_falling_slope)\n",
    "    \n",
    "    # # Ratio of t1 and pulse interval time (tpi)\n",
    "    # t1_tpi_ratio = time_between_peaks / pulse_interval\n",
    "    # features.append(t1_tpi_ratio)\n",
    "\n",
    "    # # Ratio of t2 and pulse interval time (tpi)\n",
    "    # t2_tpi_ratio = half_systolic_peak_time / pulse_interval\n",
    "    # features.append(t2_tpi_ratio)\n",
    "\n",
    "    # # Ratio of t3 and pulse interval time (tpi)\n",
    "    # t3_tpi_ratio = (peaks[1] - valleys[1]) / sampling_rate / pulse_interval\n",
    "    # features.append(t3_tpi_ratio)\n",
    "\n",
    "    # # Ratio of deltaT and pulse interval time (tpi)\n",
    "    # deltaT_tpi_ratio = (valleys[1] - peaks[0]) / sampling_rate / pulse_interval\n",
    "    # features.append(deltaT_tpi_ratio)\n",
    "    \n",
    "    # # Interval time from first PPG cycle start point (l1) in first derivative of PPF (Sf) to first maxima (a1) of Sf\n",
    "    # ta1 = peaks[0] - valleys[0]\n",
    "    # features.append(ta1)\n",
    "\n",
    "    # # Interval time from point l1 to first minima of first PPG cycle (b1) in the Sf\n",
    "    # tb1 = valleys[0] - peaks[0]\n",
    "    # features.append(tb1)\n",
    "    \n",
    "    # # Interval time from point l1 to second minima of the first PPG cycle (f1) in the Sf\n",
    "    # tf1 = valleys[1] - peaks[0]\n",
    "    # features.append(tf1)\n",
    "    \n",
    "    # # Ratio of first minima (b2) and first maxima (a2) in the second derivative of PPG signal (Sf2)\n",
    "    # b2_a2_ratio = second_derivative[valleys[0]] / second_derivative[peaks[0]]\n",
    "    # features.append(b2_a2_ratio)\n",
    "    \n",
    "    # # Ratio od second maxima (e2) in Sf2 and a2\n",
    "    # e2_a2_ratio = second_derivative[peaks[1]] / second_derivative[peaks[0]]\n",
    "    # features.append(e2_a2_ratio)\n",
    "    \n",
    "    # # Ratio of (b2+e2) and a2 [40]\n",
    "    # b2_e2_a2_ratio = (second_derivative[valleys[0]] + second_derivative[peaks[1]]) / second_derivative[peaks[0]]\n",
    "    # features.append(b2_e2_a2_ratio)\n",
    "    \n",
    "    # # Interval time from the second PPG cycle start point (l2) in second derivative of PPG to a2\n",
    "    # ta2 = peaks[0] - valleys[0]\n",
    "    # features.append(ta2)\n",
    "    \n",
    "    # # Interval time from point l2 ti b2\n",
    "    # tb2 = valleys[0] - peaks[0]\n",
    "    # features.append(tb2)\n",
    "    \n",
    "    # # Ratio of ta1 and tpi\n",
    "    # ta1_tpi_ratio = ta1 / pulse_interval\n",
    "    # features.append(ta1_tpi_ratio)\n",
    "    \n",
    "    # # Ratio of tb1 and tpi\n",
    "    # tb1_tpi_ratio = tb1 / pulse_interval\n",
    "    # features.append(tb1_tpi_ratio)\n",
    "    \n",
    "    # # Ratio of te1 and tpi\n",
    "    # te1_tpi_ratio = (valleys[1] - peaks[0]) / sampling_rate / pulse_interval\n",
    "    # features.append(te1_tpi_ratio)\n",
    "    \n",
    "    # # Ratio of time interval of l1 (tl1) and tpi\n",
    "    # tl1_tpi_ratio = valleys[0] / sampling_rate / pulse_interval\n",
    "    # features.append(tl1_tpi_ratio)\n",
    "    \n",
    "    # # Ratio of ta2 and tpi\n",
    "    # ta2_tpi_ratio = ta2 / pulse_interval\n",
    "    # features.append(ta2_tpi_ratio)\n",
    "    \n",
    "    # # Ratio of tb2 and tpi\n",
    "    # tb2_tpi_ratio = tb2 / pulse_interval\n",
    "    # features.append(tb2_tpi_ratio)\n",
    "    \n",
    "    # # Ratio of ta1+ta2 and pulse interval (tpi)\n",
    "    # ta1_ta2_tpi_ratio = (ta1 + ta2) / pulse_interval\n",
    "    # features.append(ta1_ta2_tpi_ratio)\n",
    "    \n",
    "    # # Ratio of (tb1+tb2) and pulse interval (tpi)\n",
    "    # tb1_tb2_tpi_ratio = (tb1 + tb2) / pulse_interval \n",
    "    # features.append(tb1_tb2_tpi_ratio)\n",
    "       \n",
    "    # # Ratio of (te1+t2) and pulse interval (tpi)\n",
    "    # te1_te2_tpi_ratio = (te1_tpi_ratio + tb2_tpi_ratio)\n",
    "    # features.append(te1_te2_tpi_ratio)\n",
    "    \n",
    "    # # Ratio of tl1+t3 and pulse interval (tpi)\n",
    "    # tl1_t3_tpi_ratio = (tl1_tpi_ratio + t3_tpi_ratio)\n",
    "    # features.append(tl1_t3_tpi_ratio)\n",
    "    \n",
    "    # # Fundamental component frequency obtained from Fast Fourier Transformation (FFT)\n",
    "    # fbase = np.argmax(fft(smoothed_signal))\n",
    "    # features.append(fbase)\n",
    "    \n",
    "    # # Fundamental component magnitude from FFT\n",
    "    # fbase_magnitude = np.max(fft(smoothed_signal))\n",
    "    # features.append(fbase_magnitude)\n",
    "    \n",
    "    # # Second component frequency obtained from FFT. Such that, fbase<f2nd\n",
    "    # f2nd = np.argmax(fft(smoothed_signal[fbase:]))\n",
    "    # features.append(f2nd)\n",
    "    \n",
    "    # # Second component magnitude from FFT\n",
    "    # f2nd_magnitude = np.max(fft(smoothed_signal[fbase:]))\n",
    "    # features.append(f2nd_magnitude)\n",
    "    \n",
    "    # # Third component frequency obtained from FFT. Such that, fbase<f2nd<f3rd\n",
    "    # f3rd = np.argmax(fft(smoothed_signal[f2nd:]))\n",
    "    # features.append(f3rd)\n",
    "    \n",
    "    # # Third component magnitude acquired from FFT\n",
    "    # f3rd_magnitude = np.max(fft(smoothed_signal[f2nd:]))\n",
    "    # features.append(f3rd_magnitude)\n",
    "\n",
    "    # print(\"Smoothed Signal:\", smoothed_signal)\n",
    "    # print(\"First Derivative:\", first_derivative)\n",
    "    # print(\"Second Derivative:\", second_derivative)\n",
    "\n",
    "    # # Append features to the list\n",
    "    # all_features.append(features)\n",
    "\n",
    "    # return all_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(merged_signal, sampling_rate):\n",
    "    features = {}\n",
    "    \n",
    "    peaks = argrelmax(np.array(merged_signal))[0]\n",
    "    valleys = argrelmin(np.array(merged_signal))[0]\n",
    "\n",
    "    \n",
    "    # Ensure peaks and valleys are not empty\n",
    "    if len(peaks) <=1 or len(valleys) == 0:\n",
    "        return features\n",
    "    \n",
    "   \n",
    "    derivative_1 = np.diff(merged_signal, n=1) * (sampling_rate)\n",
    "    derivative_1_peaks = argrelmax(np.array(derivative_1))[0]\n",
    "    derivative_1_valleys = argrelmin(np.array(derivative_1))[0]\n",
    "    \n",
    "    # print (derivative_1_peaks)\n",
    "    # print (derivative_1_valleys)\n",
    "    \n",
    "    systolic_peak_height = merged_signal[peaks[0]]\n",
    "    features['systolic_peak_height'] = systolic_peak_height\n",
    "\n",
    "    diastolic_peak_height = merged_signal[peaks[1]]\n",
    "    features['diastolic_peak_height'] = diastolic_peak_height\n",
    "    \n",
    "    dicrotic_notch_height =  merged_signal[valleys[0]]\n",
    "    features['dicrotic_notch_height'] = dicrotic_notch_height\n",
    "\n",
    "    # Calculate pulse interval\n",
    "    pulse_interval = len(merged_signal) / sampling_rate\n",
    "    features['pulse_interval'] = pulse_interval\n",
    "\n",
    "    # Calculate augmentation index\n",
    "    augmentation_index = diastolic_peak_height / systolic_peak_height\n",
    "    features['augmentation_index'] = augmentation_index\n",
    "    \n",
    "    # Calculate relative augmentation index\n",
    "    relative_augmentation_index = (systolic_peak_height - diastolic_peak_height) / systolic_peak_height\n",
    "    features['relative_augmentation_index'] = relative_augmentation_index\n",
    "    \n",
    "    # Calculate ratio of z and x\n",
    "    ratio_z_x = dicrotic_notch_height / systolic_peak_height\n",
    "    features['ratio_z_x'] = ratio_z_x\n",
    "\n",
    "    # Calculate negative relative augmentation index\n",
    "    negative_relative_augmentation_index = (diastolic_peak_height - dicrotic_notch_height) / systolic_peak_height\n",
    "    features['negative_relative_augmentation_index'] = negative_relative_augmentation_index\n",
    "\n",
    "    # Calculate systolic peak time\n",
    "    systolic_peak_time = (peaks[0]+1) / sampling_rate\n",
    "    features['systolic_peak_time'] = systolic_peak_time\n",
    "    \n",
    "    # Calculate dicrotic notch time\n",
    "    dicrotic_notch_time = (valleys[0]+1) / sampling_rate\n",
    "    features['dicrotic_notch_time'] = dicrotic_notch_time\n",
    "    \n",
    "    # Calculate diastolic peak time\n",
    "    diastolic_peak_time = (peaks[1]+1) / sampling_rate\n",
    "    features['diastolic_peak_time'] = diastolic_peak_time\n",
    "    \n",
    "    # Calculate time between systolic and diastolic peaks\n",
    "    time_between_peaks = diastolic_peak_time - systolic_peak_time\n",
    "    features['time_between_peaks'] = time_between_peaks\n",
    "    \n",
    "\n",
    "    \n",
    "    # Calculate time between half systolic peak points\n",
    "    half_systolic_peak_points = max(merged_signal) / 2\n",
    "    width = 0\n",
    "    for value in merged_signal[peaks[0]::-1]:\n",
    "        if value >= half_systolic_peak_points:\n",
    "            width += 1\n",
    "        else:\n",
    "            break\n",
    "    for value in merged_signal[peaks[0]+1:]:\n",
    "        if value >= half_systolic_peak_points:\n",
    "            width += 1\n",
    "        else:\n",
    "            break\n",
    "    time_between_half_systolic_peak_points= width / sampling_rate\n",
    "    features['time_between_half_systolic_peak_points']=time_between_half_systolic_peak_points\n",
    "    \n",
    "  \n",
    "    # Inflection point area ratio\n",
    "    inflection_point_area_ratio=sum(merged_signal[:peaks[0]]) / sum(merged_signal[peaks[0]:])\n",
    "    features['inflection_point_area_ratio'] = inflection_point_area_ratio\n",
    "    \n",
    "    # Systolic peak rising slope\n",
    "    systolic_peak_rising_slope=(systolic_peak_time / systolic_peak_height)\n",
    "    features['systolic_peak_rising_slope']=systolic_peak_rising_slope\n",
    "    \n",
    "    # Diastolic peak falling slope\n",
    "    diastolic_peak_falling_slope=(diastolic_peak_height / pulse_interval-diastolic_peak_time)\n",
    "    features['diastolic_peak_falling_slope']=diastolic_peak_falling_slope\n",
    "    \n",
    "    # Ratio of t1 and pulse interval time (tpi)\n",
    "    t1_tpi_ratio = systolic_peak_time / pulse_interval\n",
    "    features['t1_tpi_ratio'] = t1_tpi_ratio\n",
    "    \n",
    "    # Ratio of t2 and pulse interval time (tpi)\n",
    "    t2_tpi_ratio = dicrotic_notch_time/ pulse_interval\n",
    "    features['t2_tpi_ratio'] = t2_tpi_ratio\n",
    "    \n",
    "    # Ratio of t3 and pulse interval time (tpi)\n",
    "    t3_tpi_ratio = diastolic_peak_time / pulse_interval\n",
    "    features['t3_tpi_ratio'] = t3_tpi_ratio\n",
    "    \n",
    "    # Ratio of deltaT and pulse interval time (tpi)\n",
    "    deltaT_tpi_ratio = time_between_peaks / pulse_interval\n",
    "    features['deltaT_tpi_ratio'] = deltaT_tpi_ratio\n",
    "    \n",
    "    # Interval time from first PPG cycle start point (l1) in first derivative of PPF (Sf) to first maxima \n",
    "    lf_from_sf_to_maxima = (derivative_1_peaks[0]) / (sampling_rate)\n",
    "    features['lf_from_sf_to_maxima'] = lf_from_sf_to_maxima\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cap_vec = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    # Get the counts of values in each bin\n",
    "    bin_counts = df_binned[col].value_counts()\n",
    "\n",
    "    # Find the largest bin\n",
    "    largest_bin = bin_counts.idxmax()\n",
    "\n",
    "    # Get the largest bin intervals to find adjacent bins\n",
    "    largest_interval_left = largest_bin.left\n",
    "    largest_interval_right = largest_bin.right\n",
    "\n",
    "    # Find adjacent bins\n",
    "    adjacent_right = None\n",
    "    adjacent_left = None\n",
    "    for interval in interval_bins[col]:\n",
    "        interval_left = interval.left\n",
    "        interval_right = interval.right\n",
    "        if interval_left == largest_interval_right:\n",
    "            adjacent_right = interval\n",
    "        if interval_right == largest_interval_left:\n",
    "            adjacent_left = interval\n",
    "\n",
    "    # Get the indices of the largest bin and its adjacent bins\n",
    "    largest_bin_idx = bin_counts.index.get_loc(largest_bin)\n",
    "    left_adjacent_bin_idx = bin_counts.index.get_loc(adjacent_left)\n",
    "    right_adjacent_bin_idx = bin_counts.index.get_loc(adjacent_right)\n",
    "\n",
    "    # Extract the bins and their counts\n",
    "    largest_bin_count = bin_counts.iloc[largest_bin_idx]\n",
    "    left_adjacent_bin_count = bin_counts.iloc[left_adjacent_bin_idx]\n",
    "    right_adjacent_bin_count = bin_counts.iloc[right_adjacent_bin_idx]\n",
    "    total_count = largest_bin_count + left_adjacent_bin_count + right_adjacent_bin_count\n",
    "\n",
    "    # Extract values from the largest bin and adjacent bins\n",
    "    largest_bin_values = df[df[col].apply(lambda x: x in largest_bin)]\n",
    "    adjacent_left_values = df[df[col].apply(lambda x: x in adjacent_left)]\n",
    "    adjacent_right_values = df[df[col].apply(lambda x: x in adjacent_right)]\n",
    "\n",
    "    # Calculate the averaged value\n",
    "    averaged_value = (largest_bin_values[col].sum() + adjacent_left_values[col].sum() + adjacent_right_values[col].sum()) / total_count\n",
    "\n",
    "    # Update the final feature vector f^ for the subject\n",
    "    f_cap_vec[col] = averaged_value\n",
    "\n",
    "# Print the final feature vector\n",
    "print(\"Final feature vector:\")\n",
    "print(f_cap_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cap_vec={}\n",
    "\n",
    "\n",
    "# Get the counts of values in each bin\n",
    "bin_counts = df_binned['systolic_peak_height'].value_counts()\n",
    "\n",
    "# Find the largest bin\n",
    "largest_bin = bin_counts.idxmax()\n",
    "\n",
    "# Get the largest bin intervals to find adjacent bins\n",
    "largest_interval_left = largest_bin.left\n",
    "largest_interval_right = largest_bin.right\n",
    "\n",
    "\n",
    "#find adjacent bins\n",
    "adjacent_right=[]\n",
    "adjacent_left=[]\n",
    "for interval in interval_bins['systolic_peak_height']:\n",
    "    interval_left = interval.left\n",
    "    interval_right = interval.right\n",
    "    # print(interval,interval_left, interval_right)\n",
    "    if interval_left==largest_interval_right:\n",
    "        adjacent_right=interval\n",
    "    if interval_right==largest_interval_left:\n",
    "        adjacent_left=interval\n",
    "\n",
    "# Get the indices of the largest bin and its adjacent bins\n",
    "largest_bin_idx = bin_counts.index.get_loc(largest_bin)\n",
    "left_adjacent_bin_idx =bin_counts.index.get_loc(adjacent_left)\n",
    "right_adjacent_bin_idx =bin_counts.index.get_loc(adjacent_right)\n",
    "\n",
    "# Extract the bins and their counts\n",
    "largest_bin_count = bin_counts.iloc[largest_bin_idx]\n",
    "left_adjacent_bin_count = bin_counts.iloc[left_adjacent_bin_idx]\n",
    "right_adjacent_bin_count = bin_counts.iloc[right_adjacent_bin_idx]\n",
    "total_count=largest_bin_count + left_adjacent_bin_count + right_adjacent_bin_count\n",
    "\n",
    "# Extract values from the largest bin and adjacent bins\n",
    "largest_bin_values = df[df['systolic_peak_height'].apply(lambda x: x in largest_bin)]\n",
    "adjacent_left_values = df[df['systolic_peak_height'].apply(lambda x: x in adjacent_left)]\n",
    "adjacent_right_values = df[df['systolic_peak_height'].apply(lambda x: x in adjacent_right)]\n",
    "\n",
    "# Calculate the averaged value\n",
    "averaged_value= (largest_bin_values['systolic_peak_height'].sum() + adjacent_left_values['systolic_peak_height'].sum() + adjacent_right_values['systolic_peak_height'].sum())/total_count\n",
    "\n",
    "# Update the final feature vector f^ for the subject\n",
    "f_cap_vec['systolic_peak_height']=averaged_value"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
